{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Random Seed:  1234\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\n新しいフォルダを作成し、データセットをtrainとvalに振り分けるスクリプト\\n\\ntrain -----n000001 \\n        |--n000002 \\n        |\\u3000…\\n        |\\u3000…\\n        |--n000009 \\n\\n    ↓\\n\\ntrain2------train-----n000001 \\n         |         |--n000002 \\n         |         |-- …\\n         |         |--n000009 \\n         |\\n         |---val------n000001 \\n                   |--n000002 \\n                   | \\u3000…\\n                   |--n000009 \\n'"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_optimizer as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "#Advanced Pytorchから\n",
    "import glob\n",
    "import os.path as osp\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set random seem for reproducibility\n",
    "manualSeed = 1234\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "\n",
    "torch.torch.backends.cudnn.benchmark = True\n",
    "torch.torch.backends.cudnn.enabled = True\n",
    "\n",
    "\n",
    "'''\n",
    "新しいフォルダを作成し、データセットをtrainとvalに振り分けるスクリプト\n",
    "\n",
    "train -----n000001 \n",
    "        |--n000002 \n",
    "        |　…\n",
    "        |　…\n",
    "        |--n000009 \n",
    "\n",
    "    ↓\n",
    "\n",
    "train2------train-----n000001 \n",
    "         |         |--n000002 \n",
    "         |         |-- …\n",
    "         |         |--n000009 \n",
    "         |\n",
    "         |---val------n000001 \n",
    "                   |--n000002 \n",
    "                   | 　…\n",
    "                   |--n000009 \n",
    "'''                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュール群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 入力画像の前処理をするクラス\n",
    "# 訓練時と推論時で処理が異なる\n",
    "\n",
    "\"\"\"\n",
    "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
    "    画像のサイズをリサイズし、色を標準化する。\n",
    "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    resize : int\n",
    "        リサイズ先の画像の大きさ。\n",
    "    mean : (R, G, B)\n",
    "        各色チャネルの平均値。\n",
    "    std : (R, G, B)\n",
    "        各色チャネルの標準偏差。\n",
    "\"\"\"\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'C:\\\\Datasets\\\\VGGface2\\\\train2'\n",
    "n_samples = len(data_dir)\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "print('number of classes: ' +str(len(class_names)))\n",
    "'''\n",
    "print(class_names)\n",
    "k=0\n",
    "for i in class_names:\n",
    "    print(class_names[k]+\"_train:\"+str(len(os.listdir(path='C:\\\\Datasets\\\\VGGface2\\\\train2\\\\train\\\\'+class_names[k]))))\n",
    "    k+=1\n",
    "k=0\n",
    "for i in class_names:\n",
    "    print(class_names[k]+\"_val:\"+str(len(os.listdir(path='C:\\\\Datasets\\\\VGGface2\\\\train2\\\\val\\\\'+class_names[k]))))\n",
    "    k+=1\n",
    "'''\n",
    "print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
    "print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
    "\n",
    "\n",
    "#少数の画像を可視化\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "\n",
    "#Defining early stopping class\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "#Train models\n",
    "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # to track the training loss as the model trains\n",
    "    train_loss = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_loss = []\n",
    "\n",
    "\n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
    "            \n",
    "            # record train_loss and valid_loss\n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                print('epoch:{}'.format(epoch))\n",
    "            if phase == 'val':\n",
    "                valid_loss.append(epoch_loss)\n",
    "            #print(train_loss)\n",
    "            #print(valid_loss)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      \n",
    "      # early_stopping needs the validation loss to check if it has decresed, \n",
    "      # and if it has, it will make a checkpoint of the current model\n",
    "        if phase == 'val':    \n",
    "            early_stopping(epoch_loss, model)\n",
    "                \n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        print()\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_loss, valid_loss\n",
    "\n",
    "\n",
    "#Visualize model\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convnetの調整\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch\n",
    "from efficientnet_pytorch import EfficientNet \n",
    "\n",
    "model_ft = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "num_ftrs = model_ft._fc.in_features\n",
    "model_ft._fc = nn.Linear(num_ftrs, len(class_names))\n",
    "#GPU使用\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "#損失関数を定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#https://blog.knjcode.com/adabound-memo/\n",
    "#https://pypi.org/project/torch-optimizer/\n",
    "optimizer_ft =  optim.AdaMod(\n",
    "    model_ft.parameters(),\n",
    "    lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    beta3=0.999,\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#ネットワークの確認\n",
    "print(model_ft)\n",
    "\n",
    "from torchsummary import summary\n",
    "model_ft = model_ft.to(device)\n",
    "summary(model_ft, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=10, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit7852f1e299dd41849f14c97b75dca42e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}